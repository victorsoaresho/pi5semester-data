# P.I - 5¬∫ Semestre - Sistema de Classifica√ß√£o de Score de Cr√©dito (Aprendizado de M√°quina) üí≥

Este projeto faz parte do **Projeto Integrador (P.I)** do 5¬∫ Semestre e tem como objetivo a constru√ß√£o de um modelo de **Aprendizado de M√°quina** para prever o risco de cr√©dito de clientes.

---

## üéØ Objetivo do Projeto

O objetivo principal √© classificar um cliente como sendo de **bom** ou **mau** score (mau pagador).

A aplica√ß√£o deste modelo visa:
* Reduzir os riscos de cr√©dito para a institui√ß√£o de cons√≥rcios.
* Otimizar os processos de aprova√ß√£o de cr√©dito.

---

## üë®‚Äçüíª Equipe

O projeto foi desenvolvido pelos seguintes alunos do 5¬∫ DSM:

* Victor Hugo Ferreira Soares
* Pedro Afonso Acacio da Silva
* Samuel Ribeiro Filho
* Paulo Henrique Borges de Andrade Filho

---

## üìä Conjunto de Dados

O projeto utilizou um conjunto de dados banc√°rios abrangente, contendo informa√ß√µes cadastrais, demogr√°ficas e comportamentais de clientes.

| Caracter√≠stica | Detalhe |
| :--- | :--- |
| **Registros Iniciais** | 16.650 |
| **Registros Finais (Tratados)** | 6.770 (Dispon√≠vel em `data/trusted_dataset.csv`) |
| **Vari√°vel Alvo** | `mau` (Indicadora de mau pagador: `True` = mau, `False` = bom) |
| **Exemplos de Vari√°veis** | `sexo`, `posse_de_veiculo`, `tipo_renda`, `educacao`, `idade`, `tempo_de_emprego` |

---

## ‚öôÔ∏è Pr√©-processamento e Limpeza de Dados

As etapas de pr√©-processamento foram conduzidas para garantir qualidade e coer√™ncia antes da etapa de modelagem.

1.  **Tratamento de Nulos:** Colunas categ√≥ricas (`sexo`, `tipo_renda`, `tipo_residencia`) tiveram valores ausentes imputados pela **moda** (categoria mais frequente).
2.  **Remo√ß√£o de Duplicatas:** Remo√ß√£o aplicada com `df.drop_duplicates()`, resultando na redu√ß√£o de 16.650 para **6.770 amostras**.
3.  **Padroniza√ß√£o de Vari√°veis:**
    * `idade` e `tempo_emprego` passaram por limpeza de caracteres, convers√£o de tipos e valida√ß√£o de faixa/remo√ß√£o de outliers.
4.  **Tratamento de Outliers:** Utiliza√ß√£o de **boxplots** e m√©todo **IQR** ($1.5 \times IQR$) para identificar e remover outliers, principalmente em `tempo_emprego`.
5.  **Escalonamento:** Aplica√ß√£o de **StandardScaler** e/ou **MinMaxScaler** conforme o modelo, devido √† forte assimetria em vari√°veis como `qtd_filhos` e `tempo_emprego`.

---

## üß™ Modelagem e Avalia√ß√£o

O projeto abordou o **desbalanceamento** da classe alvo (`mau` minorit√°ria) para melhorar a detec√ß√£o.

### Modelos Testados

Modelos avaliados antes do balanceamento:
* Regress√£o Log√≠stica
* Decision Tree (√Årvore de Decis√£o)
* Random Forest
* K-Nearest Neighbors (KNN)
* Gaussian Naive Bayes (GNB)

### Balanceamento e Otimiza√ß√£o

* **T√©cnica de Balanceamento:** **SMOTE** (`Synthetic Minority Over-sampling Technique`) foi aplicado no **conjunto de treino** (`X_train`, `y_train`).
* **Melhor Modelo:** O **Random Forest** destacou-se ap√≥s o SMOTE.
* **Ajuste de Hiperpar√¢metros:** Foi realizado ajuste fino com **RandomizedSearchCV** com valida√ß√£o cruzada estratificada, focado em m√©tricas F1/Recall.

### Resultados Finais do Modelo (Random Forest Ajustado)

O **Random Forest ajustado** obteve as seguintes m√©tricas no conjunto de teste:

| M√©trica | Valor |
| :--- | :--- |
| **Accuracy** | 0.9027 |
| **Precision** | 0.8813 |
| **Recall (Sensibilidade)** | **0.9331** |
| **F1-Score** | **0.9064** |

**Conclus√£o:** O **Recall de 93.31%** indica que a grande maioria dos clientes com mau score √© identificada, e o **Precision de 88.13%** evita um excesso de falsos positivos. O Random Forest ajustado apresenta o melhor *trade-off* para o objetivo de gest√£o de risco.

---

## üì¶ Artefato e Deploy

O modelo final foi serializado para deployment.

* **Serializa√ß√£o:** O artefato (pipeline completo - pr√©-processador + Random Forest tunado) foi exportado usando `joblib.dump(csf, "mymodel.joblib")`.
* **Valida√ß√£o:** A valida√ß√£o demonstrou que o artefato √© carreg√°vel e produz predi√ß√µes coerentes, com mecanismos de *fallback* para alinhamento seguro das *features* (ex: reindexa√ß√£o ap√≥s one-hot encoding).

### üí° Boas Pr√°ticas Recomendadas

1.  **Salvar o Pipeline Completo:** Garante que as transforma√ß√µes aplicadas no treino tamb√©m ocorram na infer√™ncia.
2.  **Monitoramento:** Implementar monitoramento em produ√ß√£o para *data drift* e performance.
3.  **Robustez:** Usar `OneHotEncoder` com `handle_unknown='ignore'` dentro do pipeline para robustez contra categorias novas.