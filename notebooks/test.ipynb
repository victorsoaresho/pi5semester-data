{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gIYgX_z7AOF9",
    "outputId": "2f00e81b-193e-4f15-b44d-7a8849a83803"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algoritmo detectado: DecisionTreeClassifier (module: sklearn.tree._classes)\n",
      "\n",
      "Info:\n",
      "- detected_algorithm: DecisionTreeClassifier (module: sklearn.tree._classes)\n",
      "- is_pipeline: False\n",
      "- used_columns: ['qtd_filhos', 'idade', 'tempo_emprego', 'possui_celular', 'possui_fone_comercial', 'possui_fone', 'possui_email', 'qt_pessoas_residencia', 'sexo_M', 'posse_de_veiculo_Y', 'posse_de_imovel_Y', 'tipo_renda_Commercial associate', 'tipo_renda_Pensioner', 'tipo_renda_State servant', 'tipo_renda_Student', 'tipo_renda_Working', 'educacao_Academic degree', 'educacao_Higher education', 'educacao_Incomplete higher', 'educacao_Lower secondary', 'educacao_Secondary / secondary special', 'estado_civil_Civil marriage', 'estado_civil_Married', 'estado_civil_Separated', 'estado_civil_Single / not married', 'estado_civil_Widow', 'tipo_residencia_Co-op apartment', 'tipo_residencia_House / apartment', 'tipo_residencia_Municipal apartment', 'tipo_residencia_Office apartment', 'tipo_residencia_Rented apartment', 'tipo_residencia_With parents']\n",
      "- note: Predição executada após alinhamento de colunas (one-hot / reindex).\n",
      "- pipeline_predict_error: The feature names should match those that were passed during fit.\n",
      "Feature names unseen at fit time:\n",
      "- educacao\n",
      "- estado_civil\n",
      "- posse_de_imovel\n",
      "- posse_de_veiculo\n",
      "- renda\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- educacao_Academic degree\n",
      "- educacao_Higher education\n",
      "- educacao_Incomplete higher\n",
      "- educacao_Lower secondary\n",
      "- educacao_Secondary / secondary special\n",
      "- ...\n",
      "\n",
      "- expected_columns_detected: True\n",
      "\n",
      "Predições: [False False]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def get_final_estimator(model):\n",
    "    \"\"\"\n",
    "    Se for Pipeline, retorna o estimador final (step final).\n",
    "    Caso contrário, retorna o próprio objeto.\n",
    "    \"\"\"\n",
    "    if isinstance(model, Pipeline):\n",
    "        # pipeline[-1] nem sempre funciona; vamos pegar named_steps\n",
    "        try:\n",
    "            # sklearn Pipeline tem attribute named_steps\n",
    "            last_step = list(model.named_steps.items())[-1][1]\n",
    "            return last_step\n",
    "        except Exception:\n",
    "            # fallback: acessar estimators_ ou steps\n",
    "            try:\n",
    "                return model.steps[-1][1]\n",
    "            except Exception:\n",
    "                return model\n",
    "    return model\n",
    "\n",
    "def detect_algorithm(model):\n",
    "    \"\"\"\n",
    "    Retorna o nome amigável do algoritmo (classe) usado.\n",
    "    \"\"\"\n",
    "    final = get_final_estimator(model)\n",
    "    cls_name = final.__class__.__name__\n",
    "    module = final.__class__.__module__\n",
    "    return f\"{cls_name} (module: {module})\"\n",
    "\n",
    "def try_feature_names_from_model(model):\n",
    "    \"\"\"\n",
    "    Tenta recuperar feature names esperadas a partir do objeto salvo.\n",
    "    Retorna lista de colunas ou None.\n",
    "    Procura em:\n",
    "     - model.feature_names_in_\n",
    "     - pipeline.feature_names_in_\n",
    "     - estimador final feature_names_in_\n",
    "    \"\"\"\n",
    "    # direto no objeto\n",
    "    for obj in (model, get_final_estimator(model)):\n",
    "        if hasattr(obj, \"feature_names_in_\"):\n",
    "            cols = list(getattr(obj, \"feature_names_in_\"))\n",
    "            return cols\n",
    "\n",
    "    # tentar atributo comum salvo manualmente (feature_names, feature_columns)\n",
    "    for attr in (\"feature_names\", \"feature_columns\", \"feature_cols\", \"columns\"):\n",
    "        if hasattr(model, attr):\n",
    "            cols = getattr(model, attr)\n",
    "            try:\n",
    "                return list(cols)\n",
    "            except Exception:\n",
    "                pass\n",
    "    # procurar arquivo salvo localmente\n",
    "    for fname in (\"feature_cols.pkl\", \"feature_columns.pkl\", \"feature_cols.json\", \"X_columns.pkl\", \"feature_cols.npy\"):\n",
    "        if os.path.exists(fname):\n",
    "            try:\n",
    "                if fname.endswith(\".pkl\"):\n",
    "                    return list(joblib.load(fname))\n",
    "                elif fname.endswith(\".json\"):\n",
    "                    import json\n",
    "                    with open(fname, \"r\", encoding=\"utf-8\") as f:\n",
    "                        return json.load(f)\n",
    "                elif fname.endswith(\".npy\"):\n",
    "                    return list(np.load(fname, allow_pickle=True))\n",
    "            except Exception:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "def align_input_to_expected(df_raw, expected_cols):\n",
    "    \"\"\"\n",
    "    Converte df_raw para dummies/categoricas e reindexa para expected_cols,\n",
    "    preenchendo colunas faltantes com 0.\n",
    "    \"\"\"\n",
    "    # criar dummies para todas as colunas categóricas/objeto presentes\n",
    "    dummies = pd.get_dummies(df_raw, drop_first=False)\n",
    "    # reindex na ordem correta\n",
    "    X = dummies.reindex(columns=expected_cols, fill_value=0)\n",
    "    return X\n",
    "\n",
    "def predict_with_model(model, df_raw):\n",
    "    \"\"\"\n",
    "    Fluxo principal:\n",
    "     - detecta algoritmo\n",
    "     - tenta usar o pipeline diretamente\n",
    "     - se houver erro de nomes de feature, tenta alinhar automaticamente\n",
    "    Retorna (predicoes, info_dict)\n",
    "    \"\"\"\n",
    "    info = {}\n",
    "    info[\"detected_algorithm\"] = detect_algorithm(model)\n",
    "    info[\"is_pipeline\"] = isinstance(model, Pipeline)\n",
    "    info[\"used_columns\"] = None\n",
    "    info[\"note\"] = None\n",
    "\n",
    "    # 1) Se for Pipeline, primeiro tentamos predict direto com o DataFrame cru\n",
    "    try:\n",
    "        preds = model.predict(df_raw)\n",
    "        info[\"note\"] = \"Predição executada com sucesso diretamente (pipeline aceita DataFrame cru).\"\n",
    "        # tentar inferir as colunas usadas (se pipeline tiver feature_names_in_)\n",
    "        info[\"used_columns\"] = try_feature_names_from_model(model) or list(df_raw.columns)\n",
    "        return preds, info\n",
    "    except Exception as e_pipeline:\n",
    "        # se não for pipeline ou falhou com erro de nomes, anotamos\n",
    "        info[\"pipeline_predict_error\"] = str(e_pipeline)\n",
    "\n",
    "    # 2) tentar detectar as feature names que foram usadas no fit\n",
    "    expected_cols = try_feature_names_from_model(model)\n",
    "    info[\"expected_columns_detected\"] = expected_cols is not None\n",
    "\n",
    "    if expected_cols is None:\n",
    "        # não foi possível detectar automaticamente\n",
    "        raise ValueError(\n",
    "            \"Não foi possível detectar automaticamente as colunas que o modelo espera.\\n\"\n",
    "            \"Opções:\\n\"\n",
    "            \" - Se você salvou as colunas (feature_cols) durante o treinamento, salve-as em 'feature_cols.pkl' e rode novamente.\\n\"\n",
    "            \" - Se o modelo foi salvo como Pipeline (pré-processador + estimator) carregue esse pipeline inteiro e use pipeline.predict(df_cru).\\n\"\n",
    "            \" - Se quiser, forneça manualmente a lista expected_cols e eu ajudo a reindexar.\\n\"\n",
    "        )\n",
    "\n",
    "    # 3) alinhar os dados mocados para as colunas esperadas\n",
    "    X_aligned = align_input_to_expected(df_raw, expected_cols)\n",
    "    info[\"used_columns\"] = expected_cols\n",
    "\n",
    "    # 4) prever com o modelo (convertendo para numpy se necessário)\n",
    "    try:\n",
    "        preds = model.predict(X_aligned)\n",
    "        info[\"note\"] = \"Predição executada após alinhamento de colunas (one-hot / reindex).\"\n",
    "        return preds, info\n",
    "    except Exception as e_final:\n",
    "        # último recurso: tentar com o estimador final (se pipeline) usando numpy array\n",
    "        final_est = get_final_estimator(model)\n",
    "        try:\n",
    "            preds = final_est.predict(X_aligned.values)\n",
    "            info[\"note\"] = \"Predição executada com o estimador final usando numpy array (valide ordem de colunas manualmente).\"\n",
    "            return preds, info\n",
    "        except Exception as e_final2:\n",
    "            raise RuntimeError(\n",
    "                \"Falha ao executar predict mesmo após alinhamento.\\n\"\n",
    "                f\"Erro pipeline_predict: {info.get('pipeline_predict_error')}\\n\"\n",
    "                f\"Erro final_estimator_predict: {e_final}\\n\"\n",
    "                f\"Erro final_estimator_predict_numpy: {e_final2}\\n\"\n",
    "            )\n",
    "\n",
    "# ----------------------------\n",
    "# Exemplo de uso\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Carregar modelo (altere o caminho se necessário)\n",
    "    modelo = joblib.load(\"mymodel.pkl\")\n",
    "\n",
    "    # Mostrar qual algoritmo está sendo usado\n",
    "    print(\"Algoritmo detectado:\", detect_algorithm(modelo))\n",
    "\n",
    "    # Criar dados mocados (use as colunas originais; o script tentará converter)\n",
    "    dados_mocados = pd.DataFrame([\n",
    "        {\n",
    "            \"idade\": 35,\n",
    "            \"sexo\": \"M\",\n",
    "            \"posse_de_veiculo\": 1,\n",
    "            \"posse_de_imovel\": 0,\n",
    "            \"qtd_filhos\": 2,\n",
    "            \"tipo_renda\": \"Assalariado\",\n",
    "            \"educacao\": \"Higher education\",       # use valores iguais aos do treino quando possível\n",
    "            \"estado_civil\": \"Solteiro\",\n",
    "            \"tipo_residencia\": \"Aluguel\",\n",
    "            \"renda\": 4500\n",
    "        },\n",
    "        {\n",
    "            \"idade\": 22,\n",
    "            \"sexo\": \"F\",\n",
    "            \"posse_de_veiculo\": 0,\n",
    "            \"posse_de_imovel\": 0,\n",
    "            \"qtd_filhos\": 0,\n",
    "            \"tipo_renda\": \"Bolsista\",\n",
    "            \"educacao\": \"Secondary / secondary special\",\n",
    "            \"estado_civil\": \"Casado\",\n",
    "            \"tipo_residencia\": \"Com os pais\",\n",
    "            \"renda\": 1800\n",
    "        }\n",
    "    ])\n",
    "\n",
    "    # Rodar predição via função segura\n",
    "    preds, info = predict_with_model(modelo, dados_mocados)\n",
    "\n",
    "    print(\"\\nInfo:\")\n",
    "    for k, v in info.items():\n",
    "        print(f\"- {k}: {v}\")\n",
    "\n",
    "    print(\"\\nPredições:\", preds)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
